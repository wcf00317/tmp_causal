data:
  type: "nyuv2"
  dataset_path: "../mtl_dataset/nyuv2"
  batch_size: 32   # 如果显存允许，尽量开大
  num_workers: 4
  img_size: [288, 384]

model:
  type: "causal"
  encoder_name: "resnet50"
  pretrained: True
  latent_dim_s: 1024
  latent_dim_p: 2048
  z_s_bottleneck_noise: 0.1 # 稍微加点噪声防止过拟合
  
  # 关键：开启分解头，利用你的 decomposition loss 辅助 z_p 学习
  decomposition:
    enabled: true
    normal_head_hidden: 128
    albedo_head_hidden: 128
    light_head:
      sh_degree: 2
      grayscale_prior: true

training:
  seed: 2024           # 固定种子
  epochs: 100          # 冲击 SOTA 建议 200
  optimizer: "AdamW"   # AdamW 比 Adam 泛化性更好
  learning_rate: 0.0002
  weight_decay: 0.0001   # 增加一点 decay 防止过拟合
  
  # === 时间表控制 ===
  stage0_epochs: 2     # 仅训练分解 (A*S=I)
  stage1_epochs: 0    # 强力预热 z_s (20% 时间)
  ind_warmup_epochs: 10 # CKA 慢慢介入

  lr_scheduler:
    type: "cosine"
    warmup_epochs: 5
    min_lr_factor: 0.01

losses:
  # === 核心任务 (高压策略) ===
  lambda_seg: 20.0
  lambda_depth: 10.0   # [重点] 压低 RMSE
  lambda_normal: 10.0  # [重点] 优化角度误差
  lambda_scene: 0.0
  lambda_depth_zp: 1.0

  # === 解耦 ===
  lambda_independence: 1.0 # [重点] 10.0比1.0效果好

  # === 重构 (辅助) ===
  # 既然开启了 decomposition，可以适当降低纯像素重构的权重，依赖物理重构
  alpha_recon_geom: 2.0
  beta_recon_app: 2.0
  lambda_l1_recon: 1.0

  lambda_img: 2.0
  lambda_alb_tv: 0.1 #1
  lambda_sh_gray: 0.1 #1
  lambda_xcov: 0.5
  lambda_norm: 1.0 #1