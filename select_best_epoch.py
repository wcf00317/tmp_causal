import re
import numpy as np
import pandas as pd
import argparse
import os
import sys

# ==========================================
# 0. å…¨å±€è·¯å¾„é…ç½®
# ==========================================
# è¿™é‡Œå®šä¹‰æ—¥å¿—æ‰€åœ¨çš„æ ¹ç›®å½•
BASE_LOG_DIR = "/data/chengfengwu/alrl/causal_mtl/runs/"

# ==========================================
# 1. é…ç½®åŒºåŸŸï¼šå•ä»»åŠ¡ Baseline (STL) æ•°æ®
# ==========================================
STL_BASELINES = {
    'nyuv2': {
        # è¶Šå¤§è¶Šå¥½çš„æŒ‡æ ‡ (Direction = 1)
        'mIoU': {'val': 0.2343, 'dir': 1},
        'Pixel Acc': {'val': 0.8395, 'dir': 1},
        'Scene Accuracy': {'val': 0.2793, 'dir': 1},

        # è¶Šå°è¶Šå¥½çš„æŒ‡æ ‡ (Direction = -1)
        'RMSE': {'val': 0.6681, 'dir': -1},
        'MAE': {'val': 0.4276, 'dir': -1},
        'Abs Rel': {'val': 0.1773, 'dir': -1},
    },
    'cityscapes': {
        # è¶Šå¤§è¶Šå¥½çš„æŒ‡æ ‡ (Direction = 1)
        'mIoU': {'val': 0.6099, 'dir': 1},
        'Pixel Acc': {'val': 0.9310, 'dir': 1},

        # è¶Šå°è¶Šå¥½çš„æŒ‡æ ‡ (Direction = -1)
        'RMSE': {'val': 8.7620, 'dir': -1},
        'MAE': {'val': 3.9452, 'dir': -1},
        'Abs Rel': {'val': 0.1821, 'dir': -1},
    }
}


def extract_run_id(log_content):
    """
    ä»æ—¥å¿—ä¸­æå–å®éªŒè·¯å¾„ ID
    ç›®æ ‡è¡Œç¤ºä¾‹: Loading best model from runs/2025-12-04_14-14/checkpoints...
    """
    match = re.search(r"Loading best model from (runs/[\d\-_]+)", log_content)
    if match:
        return match.group(1)
    return "Unknown Run ID"


def detect_dataset_type(log_content):
    """
    ä»æ—¥å¿—ä¸­æ£€æµ‹æ•°æ®é›†ç±»å‹
    """
    match = re.search(r"data:\s+type:\s+(\w+)", log_content)
    if match:
        return match.group(1).lower()

    if "nyu" in log_content.lower():
        return 'nyuv2'
    if "cityscape" in log_content.lower():
        return 'cityscapes'

    return 'unknown'


def parse_training_log(log_content):
    """
    è§£ææ—¥å¿—ï¼Œæå–æ¯ä¸ª Epoch çš„æŒ‡æ ‡
    """
    epoch_data = {}
    current_epoch = -1

    epoch_pattern = re.compile(r"Starting Epoch (\d+)/(\d+)")
    seg_pattern = re.compile(r"Segmentation: mIoU=([\d\.]+), Pixel Acc=([\d\.]+)")
    depth_pattern = re.compile(r"Depth:\s+RMSE=([\d\.]+), MAE=([\d\.]+), Abs Rel=([\d\.]+)")
    scene_pattern = re.compile(r"Scene Classification \(Acc\): ([\d\.|N/A]+)")

    lines = log_content.split('\n')

    for line in lines:
        epoch_match = epoch_pattern.search(line)
        if epoch_match:
            current_epoch = int(epoch_match.group(1))
            epoch_data[current_epoch] = {}
            continue

        if current_epoch == -1:
            continue

        seg_match = seg_pattern.search(line)
        if seg_match:
            epoch_data[current_epoch]['mIoU'] = float(seg_match.group(1))
            epoch_data[current_epoch]['Pixel Acc'] = float(seg_match.group(2))

        depth_match = depth_pattern.search(line)
        if depth_match:
            epoch_data[current_epoch]['RMSE'] = float(depth_match.group(1))
            epoch_data[current_epoch]['MAE'] = float(depth_match.group(2))
            epoch_data[current_epoch]['Abs Rel'] = float(depth_match.group(3))

        scene_match = scene_pattern.search(line)
        if scene_match:
            val_str = scene_match.group(1)
            val = 0.0 if val_str == 'N/A' else float(val_str)
            epoch_data[current_epoch]['Scene Accuracy'] = val

    return epoch_data


def find_best_epoch_stl_relative(epoch_data, dataset_name):
    """
    æ ¸å¿ƒé€»è¾‘ï¼šåŸºäº Single-Task Baseline è®¡ç®—ç›¸å¯¹æå‡ç‡
    """
    if dataset_name not in STL_BASELINES:
        print(f"âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°æ•°æ®é›† '{dataset_name}' çš„ Baseline é…ç½®ã€‚")
        return None, None

    baseline_cfg = STL_BASELINES[dataset_name]

    if dataset_name == 'cityscapes' and baseline_cfg['mIoU']['val'] == 0:
        print("âš ï¸ æç¤ºï¼šCityscapes Baseline å°šæœªé…ç½®ï¼Œè¯·æ›´æ–°ä»£ç ã€‚")
        return None, None

    results = []

    for epoch, metrics in epoch_data.items():
        total_rel_score = 0
        count = 0
        row_data = {'Epoch': epoch}

        for metric_name, cfg in baseline_cfg.items():
            if metric_name not in metrics:
                continue

            val_mtl = metrics[metric_name]
            val_stl = cfg['val']
            direction = cfg['dir']

            row_data[metric_name] = val_mtl

            # è®¡ç®—ç›¸å¯¹æå‡ç‡
            if direction == 1:  # è¶Šå¤§è¶Šå¥½
                score = (val_mtl - val_stl) / val_stl
            else:  # è¶Šå°è¶Šå¥½
                score = (val_stl - val_mtl) / val_stl

            total_rel_score += score
            count += 1

        if count > 0:
            avg_score = total_rel_score / count
            row_data['Relative Score'] = avg_score
            results.append(row_data)

    if not results:
        return None, None

    df = pd.DataFrame(results)
    df.set_index('Epoch', inplace=True)
    best_epoch = df['Relative Score'].idxmax()
    return best_epoch, df


# ================= ä¸»ç¨‹åºå…¥å£ =================

if __name__ == "__main__":
    # 1. è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description="æ ¹æ® Run ID è‡ªåŠ¨åˆ†æ run.log å¹¶é€‰æ‹©æœ€ä½³ Epoch")
    parser.add_argument("run_name", type=str, help="å®éªŒæ–‡ä»¶å¤¹åç§° (ä¾‹å¦‚: 2025-12-04_14-14)")
    args = parser.parse_args()

    # 2. æ‹¼æ¥å®Œæ•´è·¯å¾„
    log_file_path = os.path.join(BASE_LOG_DIR, args.run_name, "run.log")

    print(f"ğŸ“‚ æ­£åœ¨åˆ†ææ—¥å¿—æ–‡ä»¶: {log_file_path}")

    try:
        with open(log_file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # 3. æå–å¹¶æ‰“å° Run ID (æœ¬æ¬¡å®éªŒçš„æ ‡è¯†)
        run_id = extract_run_id(content)

        # 4. è‡ªåŠ¨è¯†åˆ«æ•°æ®é›†
        dataset_type = detect_dataset_type(content)
        print(f"ğŸ” æ£€æµ‹åˆ°æ•°æ®é›†ç±»å‹: {dataset_type.upper()}")

        # 5. æ‰“å°å½“å‰ä½¿ç”¨çš„ Baseline å€¼
        if dataset_type in STL_BASELINES:
            print("\nğŸ“Š ä½¿ç”¨çš„ Single-Task Baseline å‚è€ƒå€¼:")
            print("-" * 40)
            print(f"{'Metric':<15} | {'STL Value':<10} | {'Direction'}")
            print("-" * 40)
            for k, v in STL_BASELINES[dataset_type].items():
                direction_str = "â†‘ (Higher is better)" if v['dir'] == 1 else "â†“ (Lower is better)"
                print(f"{k:<15} | {v['val']:<10.4f} | {direction_str}")
            print("-" * 40)

        # 6. è§£ææ•°æ®
        data = parse_training_log(content)
        print(f"\nâœ… è§£æå®Œæˆï¼Œå…±æå–äº† {len(data)} ä¸ª Epoch çš„æ•°æ®ã€‚")

        # 7. è®¡ç®—æœ€ä½³ Epoch
        best_ep, df_res = find_best_epoch_stl_relative(data, dataset_type)

        if best_ep:
            print(f"ğŸ† ç»¼åˆæ¨èçš„æœ€ä½³æ¨¡å‹ (Epoch {best_ep})")
            print(f"   å¹³å‡ç›¸å¯¹æå‡ç‡: {df_res.loc[best_ep]['Relative Score']:.2%} (vs Single-Task)")
            print("=" * 60)
            print("\n[Output Dictionary]:")
            print(data[best_ep])
            print(f"ğŸ“‚ å®éªŒæ—¥å¿—æ ‡è¯† (Run ID): {run_id}")

    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼š\n{log_file_path}")
        sys.exit(1)