import sys
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from tqdm import tqdm
import argparse
import yaml

# --- å¯¼å…¥æ‚¨çš„æ¨¡åž‹å®šä¹‰ ---
# ç¡®ä¿è„šæœ¬åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œï¼Œæˆ–è€…å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° PYTHONPATH
from models.causal_model import CausalMTLModel


# =========================================================================
# 1. ä¸¥æ ¼å¤åˆ»çš„æ•°æ®é›†å®šä¹‰ (å®Œå…¨éµå®ˆæ‚¨çš„ LibMTL ä»£ç æ ¼å¼)
# =========================================================================
class CityscapesC_Dataset(Dataset):
    def __init__(self, images_dir, gt_root):
        self.gt_root = gt_root
        self.img_paths = []

        # ä¸¥æ ¼å­—å…¸åºè¯»å–
        if os.path.exists(images_dir):
            subfolders = sorted([d for d in os.listdir(images_dir)
                                 if os.path.isdir(os.path.join(images_dir, d))])
            if len(subfolders) > 0:
                for city in subfolders:
                    city_path = os.path.join(images_dir, city)
                    files = sorted([f for f in os.listdir(city_path) if f.endswith('.png')])
                    for f in files:
                        self.img_paths.append(os.path.join(city_path, f))
            else:
                files = sorted([f for f in os.listdir(images_dir) if f.endswith('.png')])
                for f in files:
                    self.img_paths.append(os.path.join(images_dir, f))

        self.length = len(self.img_paths)

    def __len__(self):
        return self.length

    def __getitem__(self, idx):
        img_path = self.img_paths[idx]

        # --- è¾“å…¥å¤„ç†ï¼šä¸¥æ ¼éµå¾ª LibMTL çš„ Resize(256, 128) -> Tensor ---
        # æ³¨æ„ï¼šPIL resize å‚æ•°æ˜¯ (W, H)ï¼Œæ‰€ä»¥è¿™é‡Œæ˜¯ W=256, H=128
        img_pil = Image.open(img_path).convert('RGB')
        img_resized = img_pil.resize((256, 128), resample=Image.BILINEAR)

        # LibMTL é¢„å¤„ç†ï¼šå½’ä¸€åŒ–åˆ° [0, 1]
        img_np = np.array(img_resized).astype(np.float32) / 255.0
        img_tensor = torch.from_numpy(img_np).permute(2, 0, 1).float()

        # --- GT è¯»å–ï¼šç›´æŽ¥è¯»å– NPYï¼Œä¸åšä»»ä½•ç¼©æ”¾ ---
        # å‡è®¾ gt_root ä¸‹ç»“æž„ä¸º val/label/*.npy å’Œ val/depth/*.npy
        label_path = os.path.join(self.gt_root, 'val', 'label', f'{idx}.npy')
        depth_path = os.path.join(self.gt_root, 'val', 'depth', f'{idx}.npy')

        try:
            label = torch.from_numpy(np.load(label_path)).long()
            if os.path.exists(depth_path):
                depth = torch.from_numpy(np.load(depth_path)).float()
            else:
                depth = torch.zeros_like(label).float()
        except Exception:
            # å¼‚å¸¸å¤„ç†ï¼šè¿”å›žå…¨é›¶
            label = torch.zeros((128, 256)).long()
            depth = torch.zeros((128, 256)).float()

        return img_tensor, {'segmentation': label, 'depth': depth}


# =========================================================================
# 2. è¯„ä¼°é€»è¾‘ (é€‚é… CausalMTLModel)
# =========================================================================
def process_preds_aligned(outputs):
    """
    å°†æ¨¡åž‹è¾“å‡ºå¯¹é½åˆ° (128, 256) å¹¶é‡å‘½åé”®å€¼ä»¥åŒ¹é…è¯„ä¼°é€»è¾‘ã€‚
    """
    target_size = (128, 256)  # (H, W)
    processed = {}

    # æ˜ å°„é”®å: CausalMTL (pred_seg) -> LibMTL (segmentation)
    key_map = {
        'pred_seg': 'segmentation',
        'pred_depth': 'depth'
    }

    for k_model, k_eval in key_map.items():
        if k_model in outputs:
            pred = outputs[k_model]
            # æ’å€¼åˆ° 128x256
            if pred.shape[-2:] != target_size:
                pred = F.interpolate(pred, size=target_size, mode='bilinear', align_corners=True)
            processed[k_eval] = pred

    return processed


def evaluate(model, loader, device, num_classes=19):
    model.eval()

    # æ ¹æ®æ¨¡åž‹ç±»åˆ«æ•°åˆå§‹åŒ–æ··æ·†çŸ©é˜µ (åŽŸä»£ç æ˜¯ç¡¬ç¼–ç 7ï¼Œè¿™é‡Œæ”¹ä¸ºåŠ¨æ€è¯»å–)
    conf_mat = np.zeros((num_classes, num_classes))

    depth_abs_err = 0.0
    depth_rel_err = 0.0
    depth_count = 0

    with torch.no_grad():
        for img, gts in tqdm(loader, leave=False, desc="Eval"):
            img = img.to(device)

            # 1. æ¨¡åž‹æŽ¨ç†
            outputs = model(img, stage=2)  # ä½¿ç”¨ stage=2 (å…¨æ¨¡åž‹) è¿›è¡ŒæŽ¨ç†

            # 2. å¯¹é½å¤„ç† (Output=128x256)
            preds = process_preds_aligned(outputs)

            # --- Segmentation Evaluation ---
            if 'segmentation' in preds:
                s_pred = preds['segmentation'].argmax(1).cpu().numpy()
                s_gt = gts['segmentation'].numpy()

                # è¿‡æ»¤éžæ³•æ ‡ç­¾ (0 ~ num_classes-1)
                mask = (s_gt >= 0) & (s_gt < num_classes)
                if mask.sum() > 0:
                    # bincount è®¡ç®—æ··æ·†çŸ©é˜µ
                    conf_mat += np.bincount(
                        num_classes * s_gt[mask].astype(int) + s_pred[mask],
                        minlength=num_classes ** 2
                    ).reshape(num_classes, num_classes)

            # --- Depth Evaluation ---
            if 'depth' in preds:
                d_pred = preds['depth']
                # å¦‚æžœæ˜¯ [B, 1, H, W] -> Squeeze ä¸º [B, H, W]
                if d_pred.dim() == 4:
                    d_pred = d_pred.squeeze(1)

                d_gt = gts['depth'].to(device)

                # å¼ºåˆ¶ d_gt ä¸Ž d_pred å½¢çŠ¶ä¸€è‡´
                if d_gt.shape != d_pred.shape:
                    d_gt = d_gt.view_as(d_pred)

                # åªåœ¨ GT > 0 çš„åœ°æ–¹è¯„ä¼°
                valid = d_gt > 0
                if valid.sum() > 0:
                    pred_valid = d_pred[valid]
                    gt_valid = d_gt[valid]

                    # Abs Error
                    diff = torch.abs(pred_valid - gt_valid)
                    depth_abs_err += diff.sum().item()

                    # Rel Error
                    depth_rel_err += (diff / (gt_valid + 1e-8)).sum().item()

                    depth_count += valid.sum().item()

    # --- è®¡ç®—æœ€ç»ˆæŒ‡æ ‡ ---

    # 1. Seg mIoU
    intersection = np.diag(conf_mat)
    union = conf_mat.sum(1) + conf_mat.sum(0) - intersection
    miou = np.nanmean(intersection / (union + 1e-10))

    # 2. Seg Pix Acc
    pix_acc = intersection.sum() / (conf_mat.sum() + 1e-10)

    # 3. Depth Metrics
    abs_err = depth_abs_err / (depth_count + 1e-10)
    rel_err = depth_rel_err / (depth_count + 1e-10)

    return miou, pix_acc, abs_err, rel_err


# =========================================================================
# 3. ä¸»ç¨‹åº
# =========================================================================
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, required=True, help="æ¨¡åž‹é…ç½®æ–‡ä»¶è·¯å¾„ (.yaml)")
    parser.add_argument('--checkpoint', type=str, required=True, help="æ¨¡åž‹æƒé‡è·¯å¾„ (.pth.tar)")
    parser.add_argument('--cc_dir', type=str, required=True, help="Cityscapes-C æ•°æ®é›†æ ¹ç›®å½•")
    parser.add_argument('--gt_dir', type=str, required=True, help="é¢„å¤„ç†åŽçš„ GT æ ¹ç›®å½• (åŒ…å« val/label/*.npy)")
    parser.add_argument('--gpu_id', type=int, default=0)
    parser.add_argument('--bs', '--batch_size', type=int, default=16, dest='bs')
    parser.add_argument('--output_txt', type=str, default='eval_cc_report.txt')
    args = parser.parse_args()

    # è®¾å¤‡è®¾ç½®
    device = torch.device(f'cuda:{args.gpu_id}' if torch.cuda.is_available() else 'cpu')
    print(f"ðŸš€ Using device: {device}")

    # 1. åŠ è½½é…ç½®
    with open(args.config, 'r') as f:
        config = yaml.safe_load(f)

    # 2. åˆå§‹åŒ–æ¨¡åž‹
    print("âš™ï¸ Building CausalMTLModel...")
    # æ³¨æ„ï¼šè¿™é‡Œå¯èƒ½ä¼šæŠ¥ 'data_config' key errorï¼Œå¦‚æžœæ‚¨çš„ config ç»“æž„ä¸åŒã€‚
    # å‡è®¾ config åŒ…å« 'model' å’Œ 'data' å­—æ®µã€‚
    model = CausalMTLModel(config['model'], config['data']).to(device)

    # 3. åŠ è½½æƒé‡
    print(f"ðŸ“¥ Loading checkpoint: {args.checkpoint}")
    checkpoint = torch.load(args.checkpoint, map_location=device)
    if 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
    else:
        state_dict = checkpoint

    try:
        model.load_state_dict(state_dict, strict=True)
        print("âœ… Weights loaded (Strict).")
    except Exception as e:
        print(f"âš ï¸ Strict load failed, trying non-strict... {e}")
        model.load_state_dict(state_dict, strict=False)
        print("âœ… Weights loaded (Non-Strict).")

    # èŽ·å–ç±»åˆ«æ•° (Cityscapes é€šå¸¸æ˜¯ 19 ç±»ï¼Œä½†æ‚¨çš„é¢„å¤„ç†æ•°æ®å¦‚æžœæ˜¯ 7 ç±»ï¼Œè¿™é‡Œéœ€è¦åŒ¹é…)
    # ä¼˜å…ˆè¯»å– config ä¸­çš„ num_seg_classesï¼Œé»˜è®¤ä¸º 19
    num_classes = config['model'].get('num_seg_classes', 19)
    print(f"â„¹ï¸ Evaluating with {num_classes} segmentation classes.")

    # 4. å‡†å¤‡è®°å½•
    if not os.path.exists(args.cc_dir):
        print(f"âŒ Error: Cannot find Cityscapes-C dir: {args.cc_dir}")
        return
    if not os.path.exists(os.path.join(args.gt_dir, 'val', 'label')):
        print(f"âŒ Error: Cannot find GT labels at: {args.gt_dir}/val/label/")
        return

    corruptions = sorted([d for d in os.listdir(args.cc_dir) if os.path.isdir(os.path.join(args.cc_dir, d))])

    f_log = open(args.output_txt, 'w')

    def log(msg):
        print(msg)
        f_log.write(msg + '\n')
        f_log.flush()

    log(f"ðŸš€ Start Eval on Cityscapes-C")
    log(f"Config: {args.config}")
    log(f"Checkpoint: {args.checkpoint}")
    log(f"-" * 60)

    # 5. å¾ªçŽ¯è¯„æµ‹
    for corruption in corruptions:
        log(f"\n[Corruption: {corruption}]")
        metrics_sum = {'mIoU': 0, 'PixAcc': 0, 'AbsErr': 0, 'RelErr': 0}

        for severity in range(1, 6):
            # æž„é€ æ•°æ®é›†
            dataset = CityscapesC_Dataset(
                images_dir=os.path.join(args.cc_dir, corruption, str(severity)),
                gt_root=args.gt_dir
            )

            if len(dataset) == 0:
                print(f"  Warning: No images found for {corruption} level {severity}")
                continue

            loader = DataLoader(dataset, batch_size=args.bs, shuffle=False, num_workers=4, pin_memory=True)

            # æ‰§è¡Œè¯„ä¼°
            miou, pix_acc, abs_err, rel_err = evaluate(model, loader, device, num_classes=num_classes)

            log(f"  Level {severity}: mIoU={miou:.4f} | PixAcc={pix_acc:.4f} | AbsErr={abs_err:.4f} | RelErr={rel_err:.4f}")

            metrics_sum['mIoU'] += miou
            metrics_sum['PixAcc'] += pix_acc
            metrics_sum['AbsErr'] += abs_err
            metrics_sum['RelErr'] += rel_err

        log(f"  >> Avg ({corruption}): mIoU={metrics_sum['mIoU'] / 5:.4f} | AbsErr={metrics_sum['AbsErr'] / 5:.4f}")

    f_log.close()
    print(f"\nâœ¨ Evaluation Finished. Results saved to {args.output_txt}")


if __name__ == "__main__":
    main()