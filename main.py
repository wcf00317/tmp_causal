import yaml
import torch
import torch.optim as optim
from torch.utils.data import DataLoader
import os, argparse
import logging
from datetime import datetime

# --- æ•°æ®é›†å¯¼å…¥ ---
from data_utils.nyuv2_dataset import NYUv2Dataset
from data_utils.gta5_dataset import GTA5Dataset
from data_utils.cityscapes_dataset import CityscapesDataset

# --- æ¨¡å‹ä¸Losså¯¼å…¥ ---
from models.causal_model import CausalMTLModel
from losses.composite_loss import AdaptiveCompositeLoss
from losses.mtl_loss import MTLLoss
from models.baselines import RawMTLModel, SingleTaskModel
from losses.single_task_loss import SingleTaskLoss

# --- å¼•æ“å·¥å…·å¯¼å…¥ ---
from engine.trainer import train
from engine.visualizer import generate_visual_reports
from engine.experiments import run_all_experiments
from utils.general_utils import set_seed, setup_logging


def main(config_path):
    """
    é¡¹ç›®ä¸»å‡½æ•°ï¼ˆé€‚é… LibMTL æ•°æ®æ ¼å¼ç‰ˆï¼‰ã€‚
    """
    # 1. åŠ è½½é…ç½®å¹¶è®¾ç½®éšæœºç§å­
    try:
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        set_seed(config['training']['seed'])
    except Exception as e:
        logging.info(f"âŒ Error loading config file: {e}")
        return

    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M')
    run_dir = os.path.join('runs', timestamp)
    checkpoint_dir = os.path.join(run_dir, 'checkpoints')
    vis_dir = os.path.join(run_dir, 'visualizations')
    os.makedirs(checkpoint_dir, exist_ok=True)
    os.makedirs(vis_dir, exist_ok=True)
    setup_logging(run_dir)
    logging.info("âœ… Configuration loaded successfully.")
    logging.info(f"ğŸ“‚ All outputs for this run will be saved in: {run_dir}")

    # 2. è®¾ç½®è®¡ç®—è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logging.info(f"ğŸš€ Using device: {device}")

    # 3. åˆå§‹åŒ–æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    logging.info("\nInitializing dataset...")
    try:
        data_cfg = config['data']
        dataset_type = data_cfg.get('type', 'nyuv2').lower()
        img_size = tuple(data_cfg['img_size'])
        dataset_path = data_cfg.get('dataset_path')

        logging.info(f"ğŸ“‹ Dataset Type: {dataset_type}")
        logging.info(f"ğŸ“‚ Dataset Path: {dataset_path}")

        # === æ•°æ®é›†åŠ è½½é€»è¾‘ ===
        if dataset_type == 'gta5_to_cityscapes':
            # ... (Sim-to-Real é€»è¾‘ä¿æŒä¸å˜ï¼Œå¦‚æœéœ€è¦) ...
            train_path = data_cfg['train_dataset_path']
            val_path = data_cfg['val_dataset_path']
            train_dataset = GTA5Dataset(root_dir=train_path, img_size=img_size)
            val_dataset = CityscapesDataset(root_dir=val_path, split='val', img_size=img_size)
            # å…¼å®¹æ€§å¼•ç”¨
            full_dataset = train_dataset

        elif dataset_type == 'cityscapes':
            logging.info("ğŸŒ Mode: Cityscapes (LibMTL format)")
            train_dataset = CityscapesDataset(root_dir=dataset_path, split='train', img_size=img_size)
            val_dataset = CityscapesDataset(root_dir=dataset_path, split='val', img_size=img_size)
            full_dataset = train_dataset

        elif dataset_type == 'nyuv2':
            logging.info("ğŸ  Mode: NYUv2 (LibMTL format - Folder based)")
            # [MODIFIED] ä¸å†è¯»å– HDF5ï¼Œè€Œæ˜¯ç›´æ¥å®ä¾‹åŒ– Train/Val Dataset
            # LibMTL æ ¼å¼ä¸­ï¼Œtrain å’Œ val æ˜¯åˆ†å¼€çš„æ–‡ä»¶å¤¹ï¼Œé€šè¿‡ mode å‚æ•°æ§åˆ¶
            train_dataset = NYUv2Dataset(root_dir=dataset_path, mode='train', img_size=img_size)
            val_dataset = NYUv2Dataset(root_dir=dataset_path, mode='val', img_size=img_size)
            full_dataset = train_dataset  # ä»…ç”¨äºè·å–å±æ€§ï¼Œä¸å½±å“é€»è¾‘

        else:
            raise ValueError(f"âŒ Unsupported dataset type: '{dataset_type}'")

        # DataLoader è®¾ç½®
        pin_memory = data_cfg.get('pin_memory', torch.cuda.is_available())

        train_loader = DataLoader(
            train_dataset,
            batch_size=data_cfg['batch_size'],
            shuffle=True,
            num_workers=data_cfg['num_workers'],
            pin_memory=pin_memory,
            drop_last=True  # è®­ç»ƒæ—¶ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„ batch æœ‰åŠ©äºç¨³å®š BN
        )

        val_loader = DataLoader(
            val_dataset,
            batch_size=data_cfg['batch_size'],
            shuffle=False,
            num_workers=data_cfg['num_workers'],
            pin_memory=pin_memory
        )

        logging.info(f"ğŸ“š Dataset loaded: {len(train_dataset)} training, {len(val_dataset)} validation samples.")

    except Exception as e:
        logging.info(f"âŒ Error creating dataset/loaders: {e}")
        import traceback
        traceback.print_exc()
        return

    # 4. åˆå§‹åŒ–æ¨¡å‹
    logging.info("\nInitializing model...")
    model_type = config['model'].get('type', 'causal')
    base_lr = float(config['training']['learning_rate'])

    # å…¼å®¹æ€§å¤„ç†ï¼šä¸ºå•ä»»åŠ¡/Baselineæ¨¡å‹æä¾›å‚æ•°
    if model_type == 'raw_mtl':
        model = RawMTLModel(config['model'], config['data']).to(device)
        criterion = MTLLoss(config['losses'], use_uncertainty=(config['training'].get('strategy') == 'uncertainty')).to(
            device)
        # ç®€å•ä¼˜åŒ–å™¨é…ç½®
        optimizer = optim.Adam(model.parameters(), lr=base_lr, weight_decay=config['training']['weight_decay'])

    elif model_type == 'single_task':
        model = SingleTaskModel(config['model'], config['data']).to(device)
        criterion = SingleTaskLoss(config['model']['active_task'], config['losses']).to(device)
        optimizer = optim.Adam(model.parameters(), lr=base_lr, weight_decay=config['training']['weight_decay'])

    else:
        # é»˜è®¤ Causal Model
        model = CausalMTLModel(config['model'], config['data']).to(device)

        # å‚æ•°åˆ†ç»„ï¼šBackbone vs Heads
        # å¦‚æœæ˜¯ ResNetEncoder (wrapper)ï¼Œå®ƒçš„å‚æ•°åœ¨ model.encoder.backbone é‡Œ
        # æˆ‘ä»¬ç®€å•åœ°æŒ‰åç§°åŒºåˆ†
        backbone_params = []
        head_params = []

        for name, param in model.named_parameters():
            if 'encoder' in name:
                backbone_params.append(param)
            else:
                head_params.append(param)

        # LibMTL é»˜è®¤é…ç½®: Adam, lr=1e-4, weight_decay=1e-5
        optimizer = optim.Adam([
            {'params': backbone_params, 'lr': base_lr},  # Backbone LR
            {'params': head_params, 'lr': base_lr * 10}  # Head LR é€šå¸¸å¤§ä¸€äº› (å¯é€‰ï¼Œæˆ–è€…ä¿æŒä¸€è‡´)
        ], lr=base_lr, weight_decay=config['training']['weight_decay'])

        criterion = AdaptiveCompositeLoss(config['losses']).to(device)

    logging.info(f"ğŸ”§ Optimizer: {config['training']['optimizer']}, LR: {base_lr}")

    # 5. å­¦ä¹ ç‡è°ƒåº¦å™¨ (Scheduler)
    # é€»è¾‘å·²ç§»è‡³ engine/trainer.py ä¸­ _build_scheduler å†…éƒ¨å¤„ç†ï¼Œ
    # è¿™é‡Œä¼  None å³å¯ï¼Œtrainer ä¼šè¯»å– config è‡ªåŠ¨æ„å»º
    scheduler = None

    # 6. å¯åŠ¨è®­ç»ƒ
    logging.info("\n----- Starting Training -----")
    if config['training'].get('enable_training', True):
        train(model, train_loader, val_loader, optimizer, criterion, scheduler, config, device, checkpoint_dir)
    else:
        logging.info("ğŸƒ Training is disabled in config.")

    # 7. å®éªŒæ€§åˆ†æ (å¯é€‰)
    exp_cfg = config.get('experiments', {})
    if exp_cfg.get('enable', False):
        logging.info("\n===== Running experiments =====")
        model.eval()
        run_all_experiments(model, val_loader, device)

    # 8. å¯è§†åŒ– (å¯é€‰)
    logging.info("\n----- Running Final Visualizations -----")
    best_ckpt = os.path.join(checkpoint_dir, 'model_best.pth.tar')
    if os.path.exists(best_ckpt):
        checkpoint = torch.load(best_ckpt, map_location=device)
        model.load_state_dict(checkpoint['state_dict'], strict=False)
        generate_visual_reports(model, val_loader, device, save_dir=vis_dir, num_reports=5)

    if hasattr(train_dataset, "close"): train_dataset.close()
    if hasattr(val_dataset, "close"): val_dataset.close()

    logging.info("\nğŸ‰ Done.")


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, default='configs/resnet50_nyuv2.yaml')
    args = parser.parse_args()
    main(args.config)